# Research

A collection of papers and other open source projects that are relevant to the development of Tesseract. Can also refer to https://github.com/merrymercy/awesome-tensor-compilers
## Compilers and Code Generation

**The Deep Learning Compiler: A Comprehensive Survey**
- Paper: https://arxiv.org/abs/2002.03794

**RAF: Holistic Compilation for Deep Learning Model Training**
- Paper: https://arxiv.org/pdf/2303.04759
- GitHub: https://github.com/awslabs/raf

**Accera**
- Website: https://microsoft.github.io/Accera
- GitHub: https://github.com/microsoft/Accera

**LoopStack: a Lightweight Tensor Algebra Compiler Stack**
- Paper: https://arxiv.org/pdf/2205.00618
- GitHub: https://github.com/facebookresearch/loop_tool

**Stripe: Tensor Compilation via the Nested Polyhedral Model**
- Paper: https://arxiv.org/pdf/1903.06498v1.pdf

**Tiramisu: A Polyhedral Compiler for Expressing Fast and Portable Code**
- Paper: https://arxiv.org/pdf/1804.10694.pdf

**DNNFusion: Accelerating Deep Neural Networks Execution with Advanced Operator Fusion**
- Paper: https://dl.acm.org/doi/pdf/10.1145/3453483.3454083

**Automatic Kernel Generation for Volta Tensor Cores**
- Paper: https://arxiv.org/pdf/2006.12645v1

**Roller: Fast and Efficient Tensor Compilation for Deep Learning**
- Website: https://www.usenix.org/conference/osdi22/presentation/zhu
- Paper: https://www.usenix.org/system/files/osdi22-zhu.pdf

**Rammer: Enabling Holistic Deep Learning Compiler Optimizations with rTasks**
- Website: https://www.usenix.org/conference/osdi20/presentation/ma
- Paper: https://www.usenix.org/system/files/osdi20-ma.pdf

## Autotuning

**CompilerGym: Robust, Performant Compiler Optimization Environments for AI Research**
- Paper: https://arxiv.org/pdf/2109.08267

**LoopTune: Optimizing Tensor Computations with Reinforcement Learning**
- Paper: https://arxiv.org/pdf/2309.01825
